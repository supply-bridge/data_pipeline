import dedupe
import pandas as pd
from unidecode import unidecode

# ğŸ”¹ åŠ è½½æ•°æ®
df = pd.read_csv('mock_data.csv')
df["DUNS Number"] = df["DUNS Number"].fillna("unknown").astype(str)
data = df.to_dict(orient='records')

# ğŸ”¹ æ•°æ®é¢„å¤„ç†
def pre_process(column):
    if not isinstance(column, str):
        return 'unknown'
    processed = unidecode(column.lower().strip())
    return processed if processed else 'unknown'

for record in data:
    for key, value in record.items():
        record[key] = pre_process(value)

# å°†æ•°æ®è½¬æ¢ä¸ºdedupeéœ€è¦çš„æ ¼å¼
formatted_data = {str(i): record for i, record in enumerate(data)}
print("Total records:", len(formatted_data))

# ğŸ”¹ å®šä¹‰å»é‡æ¨¡å‹
fields = [
    dedupe.variables.Exact("DUNS Number", has_missing=True),  # å”¯ä¸€æ ‡è¯†å­—æ®µ
    dedupe.variables.String("Company Name"),  # å…è®¸æ‹¼å†™å·®å¼‚åŒ¹é…
    dedupe.variables.String("Address"),  # å…è®¸åœ°å€æ ¼å¼ä¸åŒä½†åŒ¹é…
    dedupe.variables.String("Contact"),  # è”ç³»äººæ¨¡ç³ŠåŒ¹é…
    dedupe.variables.Exact("Phone")  # ç”µè¯å®Œå…¨åŒ¹é…
]

deduper = dedupe.Dedupe(fields)

# ğŸ”¹ è®­ç»ƒæ¨¡å‹
deduper.prepare_training(formatted_data)
with open('training.json', 'w') as f:
    deduper.write_training(f)

# Add training examples
print('Starting active labeling...')
print('Please label at least 5-10 pairs of records as matches (y) and 5-10 pairs as non-matches (n)')
print('You need to provide examples of both matches and non-matches for the model to train properly')
dedupe.console_label(deduper)

deduper.train()  # è®­ç»ƒæ¨¡å‹

# ğŸ”¹ è¿›è¡Œå»é‡å’ŒåŒ¹é…
clustered_dupes = deduper.partition(formatted_data, threshold=0.6)  # è¿›è¡ŒåŒ¹é…ï¼Œ0.6 ä»£è¡¨é€‚ä¸­ä¸¥æ ¼åº¦
print("\nClustered duplicates:", clustered_dupes)

# ğŸ”¹ åˆå¹¶ç›¸ä¼¼è®°å½•
def merge_records(clustered_dupes, df):
    merged_records = []
    for cluster in clustered_dupes:
        merged = {}
        for record_id in cluster:
            record = formatted_data[record_id]
            for key, value in record.items():
                merged[key] = merged.get(key, '') or value  # é€‰å–æœ€å®Œæ•´çš„æ•°æ®
        merged_records.append(merged)
    return merged_records

final_data = merge_records(clustered_dupes, df)
final_df = pd.DataFrame(final_data)
final_df.to_csv('final_data.csv', index=False)
print("\nFinal deduplicated data saved to final_data.csv")
print(f"Original records: {len(df)}")
print(f"Deduplicated records: {len(final_df)}")
